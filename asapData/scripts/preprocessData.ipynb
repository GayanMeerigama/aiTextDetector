{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../cleanData/mergedAsap.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear  CAPS1  CAPS2  I believe that using computers will benefit us in many ways like talking and becoming friends will others through websites like facebook and mysace  Using computers can help us find coordibates  locations  and able ourselfs to millions of information  Also computers will benefit us by helping with jobs as in planning a house plan and typing a  NUM1 page report for one of our jobs in less than writing it  Now lets go into the wonder world of technology  Using a computer will help us in life by talking or making friends on line  Many people have myspace  facebooks  aim  these all benefit us by having conversations with one another  Many people believe computers are bad but how can you make friends if you can never talk to them  I am very fortunate for having a computer that can help with not only school work but my social life and how I make friends  Computers help us with finding our locations  coordibates and millions of information online  If we didn t go on the internet a lot we wouldn t know how to go onto websites that  MONTH1 help us with locations and coordinates like  LOCATION1  Would you rather use a computer or be in  LOCATION3  When your supposed to be vacationing in  LOCATION2  Million of information is found on the internet  You can as almost every question and a computer will have it  Would you rather easily draw up a house plan on the computers or take  NUM1 hours doing one by hand with ugly erazer marks all over it  you are garrenteed that to find a job with a drawing like that  Also when appling for a job many workers must write very long papers like a  NUM3 word essay on why this job fits you the most  and many people I know don t like writing  NUM3 words non stopp for hours when it could take them I hav an a computer  That is why computers we needed a lot now adays  I hope this essay has impacted your descion on computers because they are great machines to work with  The other day I showed my mom how to use a computer and she said it was the greatest invention sense sliced bread  Now go out and buy a computer to help you chat online with friends  find locations and millions of information on one click of the button and help your self with getting a job with neat  prepared  printed work that your boss will love '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Remove_Special_CharactersDf=df[\"essay\"].str.replace('\\W', ' ', regex=True)\n",
    "Remove_Special_CharactersDf\n",
    "Remove_Special_CharactersDf.loc[df.index[1]]"
    
# lemmatization is a lot more powerful. It looks beyond word reduction and considers a language’s full vocabulary to
# apply a morphological analysis to words, aiming to remove inflectional endings only and to return the base or 
# dictionary form of a word
# Wordnet is a publicly available lexical database of over 200 languages that provides semantic relationships betweenits words

#install the “popular” subset of NLTK data, on the command line type
#python -m nltk.downloader popular

import nltk
from nltk.stem import WordNetLemmatizer
nltk.download('averaged_perceptron_tagger')"
from nltk.corpus import wordnet
 
lemmatizer = WordNetLemmatizer()
  
sentence= Remove_Special_CharactersDf.loc[df.index[1]]
 
# tokenize the sentence and find the POS tag for each token
pos_tagged = nltk.pos_tag(nltk.word_tokenize(sentence)) 
  
# we use our own pos_tagger function to make things simpler to understand.
wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))

 
lemmatized_sentence = []
for word, tag in wordnet_tagged:
    if tag is None:
        # if there is no available tag, append the token as is
        lemmatized_sentence.append(word)
    else:       
        # else use the tag to lemmatize the token
        lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))
lemmatized_sentence = " ".join(lemmatized_sentence)
 
print(lemmatized_sentence)

    
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
